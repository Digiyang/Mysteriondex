{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1><center>IOT Raspberry PI und Python</center></h1>\n",
    "<h2><center>Younes Labidi & Moez Rjiba</center></h2>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"robot.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Inhalt :\n",
    "- Framework installation \n",
    "- Python motors code\n",
    "- Kamera-Stream-Code mit Bewegungserkennung\n",
    "- HTML code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Framework installation :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting Flask\n",
      "  Using cached https://files.pythonhosted.org/packages/f2/28/2a03252dfb9ebf377f40fba6a7841b47083260bf8bd8e737b0c6952df83f/Flask-1.1.2-py2.py3-none-any.whl\n",
      "Collecting click>=5.1 (from Flask)\n",
      "  Using cached https://files.pythonhosted.org/packages/d2/3d/fa76db83bf75c4f8d338c2fd15c8d33fdd7ad23a9b5e57eb6c5de26b430e/click-7.1.2-py2.py3-none-any.whl\n",
      "Collecting Werkzeug>=0.15 (from Flask)\n",
      "  Using cached https://files.pythonhosted.org/packages/cc/94/5f7079a0e00bd6863ef8f1da638721e9da21e5bacee597595b318f71d62e/Werkzeug-1.0.1-py2.py3-none-any.whl\n",
      "Collecting itsdangerous>=0.24 (from Flask)\n",
      "  Using cached https://files.pythonhosted.org/packages/76/ae/44b03b253d6fade317f32c24d100b3b35c2239807046a4c953c7b89fa49e/itsdangerous-1.1.0-py2.py3-none-any.whl\n",
      "Collecting Jinja2>=2.10.1 (from Flask)\n",
      "  Using cached https://files.pythonhosted.org/packages/30/9e/f663a2aa66a09d838042ae1a2c5659828bb9b41ea3a6efa20a20fd92b121/Jinja2-2.11.2-py2.py3-none-any.whl\n",
      "Collecting MarkupSafe>=0.23 (from Jinja2>=2.10.1->Flask)\n",
      "  Using cached https://files.pythonhosted.org/packages/fb/40/f3adb7cf24a8012813c5edb20329eb22d5d8e2a0ecf73d21d6b85865da11/MarkupSafe-1.1.1-cp27-cp27mu-manylinux1_x86_64.whl\n",
      "Installing collected packages: click, Werkzeug, itsdangerous, MarkupSafe, Jinja2, Flask\n",
      "Successfully installed Flask-1.1.2 Jinja2-2.11.2 MarkupSafe-1.1.1 Werkzeug-1.0.1 click-7.1.2 itsdangerous-1.1.0\n"
     ]
    }
   ],
   "source": [
    "! pip install Flask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flask ist ein Mikro-Web-Framework für unsere Web-Interface, mit dem wir das Auto steuern und den Live-Stream abrufen können."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://pypi.org/simple, https://www.piwheels.org/simple\n",
      "Requirement already satisfied: numpy in /usr/lib/python3/dist-packages (1.16.2)\n"
     ]
    }
   ],
   "source": [
    "! pip install numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hier verwenden wir die numpy-Bibliothek zusätzlich mit opencv- und imutils-Bibliotheken, um die Kamera auf die Web-Interface zu streamen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://pypi.org/simple, https://www.piwheels.org/simple\n",
      "Requirement already satisfied: opencv-python in /home/pi/.local/lib/python3.7/site-packages (4.1.1.26)\n",
      "Requirement already satisfied: numpy>=1.16.2 in /usr/lib/python3/dist-packages (from opencv-python) (1.16.2)\n"
     ]
    }
   ],
   "source": [
    "! pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://pypi.org/simple, https://www.piwheels.org/simple\n",
      "Requirement already satisfied: imutils in /home/pi/.local/lib/python3.7/site-packages (0.5.3)\n"
     ]
    }
   ],
   "source": [
    "! pip install imutils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Python motors code :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aufstellen von Pins an der Raspberry Pi zur Steuerung der Motoren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'RPi'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-ddaf1e51f673>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mflask\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFlask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrender_template\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mredirect\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl_for\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmake_response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mRPi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGPIO\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mGPIO\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmA1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m18\u001b[0m \u001b[0;31m#Motor1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'RPi'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from flask import Flask, render_template, request, redirect, url_for, make_response \n",
    "import time\n",
    "import RPi.GPIO as GPIO\n",
    "\n",
    "mA1=18 #Motor1\n",
    "mA2=23\n",
    "mB1=24 #Motor2\n",
    "mB2=25\n",
    "\n",
    "GPIO.setmode(GPIO.BCM)    #Referring to the pins by the \"Broadcom SOC channel\" number\n",
    "\n",
    "GPIO.setup(mA1, GPIO.OUT) #Motors GPIO as OUTPUT\n",
    "GPIO.setup(mA2, GPIO.OUT)\n",
    "GPIO.setup(mB1, GPIO.OUT)\n",
    "GPIO.setup(mB2, GPIO.OUT)\n",
    "\n",
    "GPIO.output(mA1 , 0)      #Initial values 0 \n",
    "GPIO.output(mA2 , 0)\n",
    "GPIO.output(mB1, 0)\n",
    "GPIO.output(mB2, 0)\n",
    "\n",
    "app = Flask(__name__)     #set up flask server"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normaler Fehler, da er auf einer Raspberry-PI und nicht auf einem Desktop ausgeführt wird."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route('/')\n",
    "def index():\n",
    "    return render_template('index.html')\n",
    "\n",
    "#Recieve which pin to change from the button press on index.html\n",
    "#Each button returns a number that triggers a command in this function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Uses methods from motors.py to send commands to the GPIO to operate the motors\n",
    "@app.route('/<changepin>', methods=['POST'])\n",
    "def reroute(changepin):\n",
    "    changePin = int(changepin) #cast changepin to an int\n",
    "    if changePin == 1:\n",
    "        print (\"Vorne\") # drive forward\n",
    "        GPIO.output(mA1 , 0)\n",
    "        GPIO.output(mA2 , 1)\n",
    "        GPIO.output(mB1 , 1)\n",
    "        GPIO.output(mB2 , 0)\n",
    "    elif changePin == 2:\n",
    "        print (\"Links\") # turn left\n",
    "        GPIO.output(mA1 , 0)\n",
    "        GPIO.output(mA2 , 0)\n",
    "        GPIO.output(mB1 , 1)\n",
    "        GPIO.output(mB2 , 0)\n",
    "    elif changePin == 3:\n",
    "        print (\"Stop\") # stop the car\n",
    "        GPIO.output(mA1 , 0)\n",
    "        GPIO.output(mA2 , 0)\n",
    "        GPIO.output(mB1 , 0)\n",
    "        GPIO.output(mB2 , 0)\n",
    "    elif changePin == 4:\n",
    "        print (\"Rechts\") # turn right\n",
    "        GPIO.output(mA1 , 0)\n",
    "        GPIO.output(mA2 , 1)\n",
    "        GPIO.output(mB1 , 0)\n",
    "        GPIO.output(mB2 , 0)\n",
    "    else:\n",
    "        print(\"Reverse\") # drive backwards\n",
    "        GPIO.output(mA1 , 1)\n",
    "        GPIO.output(mA2 , 0)\n",
    "        GPIO.output(mB1 , 0)\n",
    "        GPIO.output(mB2 , 1)\n",
    "    response = make_response(redirect(url_for('index')))\n",
    "    return(response)\n",
    "app.run(debug=True, host='0.0.0.0', port=8000) #set up the server in debug mode to the port 8000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Kamera-Stream-Code mit Bewegungserkennung :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"2020-06-30-121435_1920x1080_scrot.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bewegungserkennungsalgorithmus, der Numpy für die numerische Verarbeitung, Imutils für unsere Komfortfunktionen und cv2 für OpenCV-Bindungen verwendet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unser Bewegungsmelder-Algorithmus erkennt Bewegung durch eine Form der Hintergrundsubtraktion.\n",
    "\n",
    "Der Subtraktionsalgorithmus arbeitet nach:\n",
    "\n",
    "    1- Akkumulieren des gewichteten Mittelwertes der vorherigen N Bilder\n",
    "    2- Nehmen Sie den aktuellen Rahmen und subtrahieren Sie ihn vom gewichteten Durchschnitt der Rahmen\n",
    "    3- Schwellenwert für die Ausgabe der Subtraktion, um die Regionen mit erheblichen Unterschieden in den Pixelwerten hervorzuheben (\"weiß\" für den Vordergrund und \"schwarz\" für den Hintergrund)\n",
    "    4- Anwendung grundlegender Bildverarbeitungstechniken wie Erosionen und Dilatationen, um Rauschen zu entfernen\n",
    "    5- Verwendung der Konturerkennung zur Extraktion der Regionen, die eine Bewegung enthalten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unsere Bewegungserkennungs-Implementierung wird innerhalb der SingleMotionDetector-Klasse leben, die in singleMotionDetector.py zu finden ist.\n",
    "\n",
    "Sie wird als \"Einzelbewegungsmelder\" bezeichnet, da der Algorithmus selbst nur daran interessiert ist, die größte einzelne Bewegungsregion zu finden.\n",
    "\n",
    "Wir können diese Methode leicht erweitern, um auch mehrere Bewegungsregionen zu behandeln.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "/home/pi/.local/lib/python3.7/site-packages/cv2/cv2.cpython-37m-arm-linux-gnueabihf.so: undefined symbol: __atomic_fetch_add_8",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-ea8c565de04b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# import the necessary packages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mimutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/imutils/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# import the necessary packages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mconvenience\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtranslate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mconvenience\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrotate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mconvenience\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrotate_bound\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/imutils/convenience.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# import the necessary packages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/cv2/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcv2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: /home/pi/.local/lib/python3.7/site-packages/cv2/cv2.cpython-37m-arm-linux-gnueabihf.so: undefined symbol: __atomic_fetch_add_8"
     ]
    }
   ],
   "source": [
    "# import the necessary packages\n",
    "import numpy as np\n",
    "import imutils\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wenn Sie diesen Importfehler erhalten, führen Sie Ihr Programm einfach mit diesem Befehl aus:\n",
    "\n",
    "LD_PRELOAD=/usr/lib/arm-linux-gnueabihf/libatomic.so.1 python3 webstreaming.py --ip 0.0.0.0 --port 8000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SingleMotionDetector:\n",
    "    def __init__(self, accumWeight=0.5):\n",
    "        # store the accumulated weight factor\n",
    "        self.accumWeight = accumWeight\n",
    "\n",
    "        # initialize the background model\n",
    "        self.bg = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Je größer accumWeight ist, desto weniger wird der Hintergrund (bg) bei der Akkumulation des gewichteten Durchschnitts berücksichtigt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def update(self, image):\n",
    "        # if the background model is None, initialize it\n",
    "        if self.bg is None:\n",
    "            self.bg = image.copy().astype(\"float\")\n",
    "            return\n",
    "\n",
    "        # update the background model by accumulating the weighted\n",
    "        # average\n",
    "        cv2.accumulateWeighted(image, self.bg, self.accumWeight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definiert eine Aktualisierungsmethode, die ein Eingabefenster akzeptiert und den gewichteten Durchschnitt berechnet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def detect(self, image, tVal=25):\n",
    "        # compute the absolute difference between the background model\n",
    "        # and the image passed in, then threshold the delta image\n",
    "        delta = cv2.absdiff(self.bg.astype(\"uint8\"), image)\n",
    "        thresh = cv2.threshold(delta, tVal, 255, cv2.THRESH_BINARY)[1]\n",
    "\n",
    "        # perform a series of erosions and dilations to remove small\n",
    "        # blobs\n",
    "        thresh = cv2.erode(thresh, None, iterations=2)\n",
    "        thresh = cv2.dilate(thresh, None, iterations=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vor unserem Hintergrund (bg) können wir nun die Bewegungserkennung mittels Detektionsmethode anwenden.\n",
    "\n",
    "Die Methode erfordert einen einzigen Parameter mit einem optionalen Parameter:\n",
    "    \n",
    "    -image: Eingabebild\n",
    "    -tval : Schwellenwert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        # find contours in the thresholded image and initialize the\n",
    "        # minimum and maximum bounding box regions for motion\n",
    "        cnts = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL,\n",
    "            cv2.CHAIN_APPROX_SIMPLE)\n",
    "        cnts = imutils.grab_contours(cnts)\n",
    "        (minX, minY) = (np.inf, np.inf)\n",
    "        (maxX, maxY) = (-np.inf, -np.inf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anwendung der Konturerkennung zum Extrahieren beliebiger Bewegungen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # if no contours were found, return None\n",
    "        if len(cnts) == 0:\n",
    "            return None\n",
    "\n",
    "        # otherwise, loop over the contours\n",
    "        for c in cnts:\n",
    "            # compute the bounding box of the contour and use it to\n",
    "            # update the minimum and maximum bounding box regions\n",
    "            (x, y, w, h) = cv2.boundingRect(c)\n",
    "            (minX, minY) = (min(minX, x), min(minY, y))\n",
    "            (maxX, maxY) = (max(maxX, x + w), max(maxY, y + h))\n",
    "\n",
    "        # otherwise, return a tuple of the thresholded image along\n",
    "        # with bounding box\n",
    "        return (thresh, (minX, minY, maxX, maxY))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir prüfen, ob unsere Konturenliste leer ist.\n",
    "\n",
    "Wenn das der Fall ist, dann wurde keine Bewegung im Rahmen gefunden, und wir können sie getrost ignorieren.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "from .singlemotiondetector import SingleMotionDetector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kombination von OpenCV mit Flask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import unseres Bewegungserkennungsalgorithmus, Flask zum Rendern unserer index.html-Vorlage und Threading, damit wir Gleichzeitigkeit unterstützen können."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USAGE\n",
    "# python webstreaming.py --ip 0.0.0.0 --port 8000\n",
    "\n",
    "# import the necessary packages\n",
    "from pyimagesearch.motion_detection import SingleMotionDetector\n",
    "from imutils.video import VideoStream\n",
    "from flask import Response\n",
    "from flask import Flask\n",
    "from flask import render_template\n",
    "import threading\n",
    "import argparse\n",
    "import datetime\n",
    "import imutils\n",
    "import time\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kombination von OpenCV und Flask zur Bereitstellung von Einzelbildern aus einem Videostream an einen Webbrowser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the output frame and a lock used to ensure thread-safe\n",
    "# exchanges of the output frames (useful for multiple browsers/tabs\n",
    "# are viewing tthe stream)\n",
    "outputFrame = None\n",
    "lock = threading.Lock()\n",
    "\n",
    "# initialize a flask object\n",
    "app = Flask(__name__)\n",
    "\n",
    "# initialize the video stream and allow the camera sensor to\n",
    "# warmup\n",
    "vs = VideoStream(usePiCamera=1).start()\n",
    "time.sleep(2.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialisierung von outputFrame, derselbe Rahmen, der auch den Kunden zur Verfügung gestellt wird.\n",
    "\n",
    "Erstellen einer Sperre, um thread-sicheres Verhalten bei der Aktualisierung des outputFrame zu gewährleisten.\n",
    "\n",
    "Initialisierung der Flask-Anwendung beim Zugriff auf den Videostream."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route(\"/\")\n",
    "def index():\n",
    "    # return the rendered template\n",
    "    return render_template(\"index.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rendern der index.html-Vorlage und Bereitstellen des Ausgabe-Videostroms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_motion(frameCount):\n",
    "    # grab global references to the video stream, output frame, and\n",
    "    # lock variables\n",
    "    global vs, outputFrame, lock\n",
    "\n",
    "    # initialize the motion detector and the total number of frames\n",
    "    # read thus far\n",
    "    md = SingleMotionDetector(accumWeight=0.1)\n",
    "    total = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diese Funktion wird verantwortlich sein:\n",
    "    \n",
    "    -Schleifen über Einzelbilder aus dem Videostrom\n",
    "    -Anwendung der Bewegungserkennung\n",
    "    -Zeichnungsergebnisse auf dem Ausgabeframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # loop over frames from the video stream\n",
    "    while True:\n",
    "        # read the next frame from the video stream, resize it,\n",
    "        # convert the frame to grayscale, and blur it\n",
    "        frame = vs.read()\n",
    "        frame = imutils.resize(frame, width=400)\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        gray = cv2.GaussianBlur(gray, (7, 7), 0)\n",
    "\n",
    "        # grab the current timestamp and draw it on the frame\n",
    "        timestamp = datetime.datetime.now()\n",
    "        cv2.putText(frame, timestamp.strftime(\n",
    "            \"%A %d %B %Y %I:%M:%S%p\"), (10, frame.shape[0] - 10),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX, 0.35, (0, 0, 255), 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir können jetzt eine Hintergrundsubtraktion durchführen und mit dem Looping über die Bilder der Kamera beginnen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        # if the total number of frames has reached a sufficient\n",
    "        # number to construct a reasonable background model, then\n",
    "        # continue to process the frame\n",
    "        if total > frameCount:\n",
    "            # detect motion in the image\n",
    "            motion = md.detect(gray)\n",
    "\n",
    "            # cehck to see if motion was found in the frame\n",
    "            if motion is not None:\n",
    "                # unpack the tuple and draw the box surrounding the\n",
    "                # \"motion area\" on the output frame\n",
    "                (thresh, (minX, minY, maxX, maxY)) = motion\n",
    "                cv2.rectangle(frame, (minX, minY), (maxX, maxY),\n",
    "                    (0, 0, 255), 2)\n",
    "        \n",
    "        # update the background model and increment the total number\n",
    "        # of frames read thus far\n",
    "        md.update(gray)\n",
    "        total += 1\n",
    "\n",
    "        # acquire the lock, set the output frame, and release the\n",
    "        # lock\n",
    "        with lock:\n",
    "            outputFrame = frame.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mit der Endkontrolle können wir nun die Bewegungserkennung durchführen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate():\n",
    "    # grab global references to the output frame and lock variables\n",
    "    global outputFrame, lock\n",
    "\n",
    "    # loop over frames from the output stream\n",
    "    while True:\n",
    "        # wait until the lock is acquired\n",
    "        with lock:\n",
    "            # check if the output frame is available, otherwise skip\n",
    "            # the iteration of the loop\n",
    "            if outputFrame is None:\n",
    "                continue\n",
    "\n",
    "            # encode the frame in JPEG format\n",
    "            (flag, encodedImage) = cv2.imencode(\".jpg\", outputFrame)\n",
    "\n",
    "            # ensure the frame was successfully encoded\n",
    "            if not flag:\n",
    "                continue\n",
    "\n",
    "        # yield the output frame in the byte format\n",
    "        yield(b'--frame\\r\\n' b'Content-Type: image/jpeg\\r\\n\\r\\n' + \n",
    "            bytearray(encodedImage) + b'\\r\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Funktion generate, ist ein Generator, der verwendet wird, um das OutputFrame als JPEG-Daten zu kodieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route(\"/video_feed\")\n",
    "def video_feed():\n",
    "    # return the response generated along with the specific media\n",
    "    # type (mime type)\n",
    "    return Response(generate(),\n",
    "        mimetype = \"multipart/x-mixed-replace; boundary=frame\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die app.route-Signatur teilt Flask mit, dass es sich bei dieser Funktion um einen URL-Endpunkt handelt und dass die Daten von http://your_ip_address/video_feed/ serviert werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check to see if this is the main thread of execution\n",
    "if __name__ == '__main__':\n",
    "    # construct the argument parser and parse command line arguments\n",
    "    ap = argparse.ArgumentParser()\n",
    "    ap.add_argument(\"-i\", \"--ip\", type=str, required=True,\n",
    "        help=\"ip address of the device\")\n",
    "    ap.add_argument(\"-o\", \"--port\", type=int, required=True,\n",
    "        help=\"ephemeral port number of the server (1024 to 65535)\")\n",
    "    ap.add_argument(\"-f\", \"--frame-count\", type=int, default=32,\n",
    "        help=\"# of frames used to construct the background model\")\n",
    "    args = vars(ap.parse_args())\n",
    "\n",
    "    # start a thread that will perform motion detection\n",
    "    t = threading.Thread(target=detect_motion, args=(\n",
    "        args[\"frame_count\"],))\n",
    "    t.daemon = True\n",
    "    t.start()\n",
    "\n",
    "    # start the flask app\n",
    "    app.run(host=args[\"ip\"], port=args[\"port\"], debug=True,\n",
    "        threaded=True, use_reloader=False)\n",
    "\n",
    "# release the video stream pointer\n",
    "vs.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diese letzte Funktion behandelt das Parsen von Befehlszeilenargumenten und das Starten der Flask-Anwendung."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HTML Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wie wir in den vorherigen Codes (Motoren, Stream) gesehen haben, rendern wir eine HTML-Vorlage mit dem Namen index.html.\n",
    "\n",
    "Die Vorlage selbst wird durch das Web-Framework Flask gefüllt und dann dem Web-Server zur Verfügung gestellt.\n",
    "\n",
    "img src=\"{{{ url_for('video_feed') }}\": Flask wird angewiesen, die URL unseres Video-Feeds dynamisch zu rendern.\n",
    "\n",
    "button id=\"FWD\" class=\"robot\">FORWARD</button: Einrichten der Steuerknöpfe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<!DOCTYPE html>\n",
    "<html>\n",
    "            <head>\n",
    "                        <title>IOT Raspberry pi und Python</title>\n",
    "                        <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\n",
    "            </head>\n",
    "<style>\n",
    "table ,td, tr {\n",
    "                        width: 30%;\n",
    "}\n",
    "</style>\n",
    "            <body>\n",
    "                        <h1>Pi Remote Stream</h1>\n",
    "                        <img src=\"{{ url_for('video_feed') }}\" style=\"float:left; width:100%; max-width: 700px; max-height:600px; border-radius:10px\"></img>\n",
    "                <table style=\"float:right; width:100%; max-width: 400px; height:300px;\">\n",
    "                 <tr style=\"text-align:center\">\n",
    "                    <td >\n",
    "                         <h4 style=\"text-align: center; color:Tomato\">IOT & Raspberry pi & Python</h4>\n",
    "                            </td>                 \n",
    "                 <tr>\n",
    "                 <tr>\n",
    "                             <td style=\"text-align: center\">\n",
    "                                    <form action=\"/1\" method=\"POST\">\n",
    "                                  <button id=\"FWD\" class=\"robot\">FORWARD</button>\n",
    "                                  </br>\n",
    "                                </form>\n",
    "                             </td>\n",
    "                 <tr>\n",
    "             <tr>\n",
    "                             <td style=\"text-align: left\">\n",
    "                     <form action=\"/2\" method=\"POST\">\n",
    "                                     <button id=\"LFT\" class=\"robot\">LEFT</button>\n",
    "                                     </br>\n",
    "                                </form>\n",
    "                             </td>\n",
    "             \n",
    "                             <td style=\"text-align: right\">\n",
    "                                    <form action=\"/4\" method=\"POST\">\n",
    "                                     <button id=\"RGT\" class=\"robot\">RIGHT</button>\n",
    "                                  </br>\n",
    "                                    </form>\n",
    "                             </td>\n",
    "                             <td >\n",
    "                                    <form action=\"/3\" method=\"POST\">\n",
    "                                     <button id=\"STP\" class=\"robot\">STOP</button>\n",
    "                                      </br>\n",
    "                                    </form>\n",
    "                     </td>                          \n",
    "                   <tr>\n",
    "                   <tr>\n",
    "                             <td style=\"text-align: center\">\n",
    "                                    <form action=\"/5\" method=\"POST\">\n",
    "                                     <button id=\"REV\" class=\"robot\">REVERSE</button>\n",
    "                                     </br>\n",
    "                                </form>\n",
    "                             </td>\n",
    "                   </tr>\n",
    "\n",
    "                        </table>\n",
    "<h4 style=\"text-align: center; color:Tomato\">By:</h4>\n",
    "<h4 style=\"text-align: center; color:Tomato; \">Younes Labidi</h4>\n",
    "<h4 style=\"text-align: center; color:Tomato; \">Moez Rjiba</h4>\n",
    "\n",
    "        </body>\n",
    "</html>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fazit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das Projekt gibt Ihnen eine Vorstellung davon, was wir mit Raspberry Pi und all den Frameworks, die Python liefern kann, tun können, um ein IOT-System zu erstellen.\n",
    "\n",
    "Das Projekt selbst kann durch die Implementierung von Sensoren optimiert und verbessert werden und es autonom machen. Wir können den Stream auch von überall her verfügbar machen, indem wir ein VPN oder eine API erstellen."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
